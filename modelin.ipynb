{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined.pickle\n",
      "dataframe_processed_0_to_29.pickle\n",
      "dataframe_processed_120_to_149.pickle\n",
      "dataframe_processed_150_to_179.pickle\n",
      "dataframe_processed_180_to_209.pickle\n",
      "dataframe_processed_210_to_239.pickle\n",
      "dataframe_processed_240_to_269.pickle\n",
      "dataframe_processed_270_to_299.pickle\n",
      "dataframe_processed_30_to_59.pickle\n",
      "dataframe_processed_60_to_89.pickle\n",
      "dataframe_processed_90_to_119.pickle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>full</th>\n",
       "      <th>full_orignal</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>appellant terminate organization workman numbe...</td>\n",
       "      <td>judgment order date date number organization h...</td>\n",
       "      <td>from the judgment and order dated march 12, 19...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>date respondent number obtain decree appellant...</td>\n",
       "      <td>rom judgment order date date number organizati...</td>\n",
       "      <td>rom the judgment and order dated march 21, 196...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>country organization limited organization*carr...</td>\n",
       "      <td>judgment order date date number calcutta high ...</td>\n",
       "      <td>the judgment and order dated january 7, 1966 o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>notice number 22(2 person tax number number co...</td>\n",
       "      <td>judgment order date date number person high or...</td>\n",
       "      <td>he judgment and order dated march 21, 1966 of ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>number b j partner firm carry business entitle...</td>\n",
       "      <td>number organization special leave judgment ord...</td>\n",
       "      <td>6. appeals by special leave from, the judgment...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>assessee company hold certain share organizati...</td>\n",
       "      <td>ls certificate special leave judgment order da...</td>\n",
       "      <td>ls by certificate/special leave from the judgm...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>organization organization officer issue notice...</td>\n",
       "      <td>ls special leave judgment order date date numb...</td>\n",
       "      <td>ls by special leave from the judgment and orde...</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>question whether amount represent interest amo...</td>\n",
       "      <td>order date date number assam nagaland high org...</td>\n",
       "      <td>and order dated august 22, 1966 of the assam a...</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>dispute date raise organization appellant comp...</td>\n",
       "      <td>award date date number organization person per...</td>\n",
       "      <td>from the award dated february 18, 1970 of the ...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>assessee firm deriving organization security p...</td>\n",
       "      <td>judgment order date date number country high o...</td>\n",
       "      <td>he judgment and order dated september 20, 1967...</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               summary   \n",
       "0    appellant terminate organization workman numbe...  \\\n",
       "1    date respondent number obtain decree appellant...   \n",
       "2    country organization limited organization*carr...   \n",
       "3    notice number 22(2 person tax number number co...   \n",
       "4    number b j partner firm carry business entitle...   \n",
       "..                                                 ...   \n",
       "595  assessee company hold certain share organizati...   \n",
       "596  organization organization officer issue notice...   \n",
       "597  question whether amount represent interest amo...   \n",
       "598  dispute date raise organization appellant comp...   \n",
       "599  assessee firm deriving organization security p...   \n",
       "\n",
       "                                                  full   \n",
       "0    judgment order date date number organization h...  \\\n",
       "1    rom judgment order date date number organizati...   \n",
       "2    judgment order date date number calcutta high ...   \n",
       "3    judgment order date date number person high or...   \n",
       "4    number organization special leave judgment ord...   \n",
       "..                                                 ...   \n",
       "595  ls certificate special leave judgment order da...   \n",
       "596  ls special leave judgment order date date numb...   \n",
       "597  order date date number assam nagaland high org...   \n",
       "598  award date date number organization person per...   \n",
       "599  judgment order date date number country high o...   \n",
       "\n",
       "                                          full_orignal   Id  \n",
       "0    from the judgment and order dated march 12, 19...    0  \n",
       "1    rom the judgment and order dated march 21, 196...    1  \n",
       "2    the judgment and order dated january 7, 1966 o...    2  \n",
       "3    he judgment and order dated march 21, 1966 of ...    3  \n",
       "4    6. appeals by special leave from, the judgment...    4  \n",
       "..                                                 ...  ...  \n",
       "595  ls by certificate/special leave from the judgm...  115  \n",
       "596  ls by special leave from the judgment and orde...  116  \n",
       "597  and order dated august 22, 1966 of the assam a...  117  \n",
       "598  from the award dated february 18, 1970 of the ...  118  \n",
       "599  he judgment and order dated september 20, 1967...  119  \n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path = \"/Users/prati/Downloads/Compressed/Extractive_Summartization-master/Necessary Codes/dataframes/\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in os.listdir(path):\n",
    "    df = pd.read_pickle(path+i)\n",
    "    df['temp_col_len'] = df.full.str.len()\n",
    "    print(i)\n",
    "    data = pd.concat([data, df[df['temp_col_len']>1].drop(columns = ['temp_col_len'])], axis = 0, ignore_index=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "       216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "       229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "       242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS_index = (np.array(data.index))[-50:]\n",
    "GS_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc No. :  12 has a problem\n",
      "Doc No. :  31 has a problem\n",
      "Doc No. :  47 has a problem\n",
      "Doc No. :  52 has a problem\n",
      "Doc No. :  68 has a problem\n",
      "Doc No. :  87 has a problem\n",
      "Doc No. :  98 has a problem\n",
      "Doc No. :  115 has a problem\n",
      "Doc No. :  118 has a problem\n",
      "Doc No. :  121 has a problem\n",
      "Doc No. :  131 has a problem\n",
      "Doc No. :  147 has a problem\n",
      "Doc No. :  150 has a problem\n",
      "Doc No. :  151 has a problem\n",
      "Doc No. :  160 has a problem\n",
      "Doc No. :  168 has a problem\n",
      "Doc No. :  185 has a problem\n",
      "Doc No. :  193 has a problem\n",
      "Doc No. :  194 has a problem\n",
      "GS Doc No. :  -855 has a problem\n",
      "GS Doc No. :  -851 has a problem\n",
      "GS Doc No. :  -839 has a problem\n",
      "Doc No. :  312 has a problem\n",
      "Doc No. :  331 has a problem\n",
      "Doc No. :  347 has a problem\n",
      "Doc No. :  352 has a problem\n",
      "Doc No. :  368 has a problem\n",
      "Doc No. :  387 has a problem\n",
      "Doc No. :  398 has a problem\n",
      "Doc No. :  415 has a problem\n",
      "Doc No. :  418 has a problem\n",
      "Doc No. :  421 has a problem\n",
      "Doc No. :  431 has a problem\n",
      "Doc No. :  447 has a problem\n",
      "Doc No. :  450 has a problem\n",
      "Doc No. :  451 has a problem\n",
      "Doc No. :  460 has a problem\n",
      "Doc No. :  468 has a problem\n",
      "Doc No. :  485 has a problem\n",
      "Doc No. :  493 has a problem\n",
      "Doc No. :  494 has a problem\n",
      "Doc No. :  505 has a problem\n",
      "Doc No. :  509 has a problem\n",
      "Doc No. :  521 has a problem\n",
      "summary sentence tokenization\n",
      "14361\n",
      "14361\n",
      "69069\n",
      "69069\n",
      "69069\n",
      "4719\n",
      "4719\n",
      "4719\n"
     ]
    }
   ],
   "source": [
    "# Sentence tokenization\n",
    "# and tagging of document number t sentences\n",
    "\n",
    "temp = data.copy()\n",
    "\n",
    "set = temp.index\n",
    "# set = np.arange(0, 51, 1)\n",
    "# set = [0, 1, 2]\n",
    "\n",
    "# temp = data\n",
    "\n",
    "full_sent = pd.DataFrame()\n",
    "summ_sent = pd.DataFrame()\n",
    "\n",
    "full_docs = []\n",
    "summ_docs = []\n",
    "GS_docs = []\n",
    "\n",
    "ori_sent = pd.DataFrame()\n",
    "GS_sent = pd.DataFrame()\n",
    "GS_ori_sent = pd.DataFrame()\n",
    "\n",
    "for i in set:\n",
    "  if i not in GS_index:\n",
    "    full = temp['full'].iloc[i]\n",
    "    summary = temp['summary'].iloc[i]\n",
    "    ori = temp['full_orignal'].iloc[i]\n",
    "    \n",
    "#     print(full)\n",
    "#     break\n",
    "    v = full.split(\"*\")    \n",
    "    t1 = pd.DataFrame(v)\n",
    "    \n",
    "    v = summary.split('*')\n",
    "    t2 = pd.DataFrame(v)\n",
    "    \n",
    "    v = ori.split('*')\n",
    "    t5 = pd.DataFrame(v)\n",
    "    \n",
    "    t3 = np.linspace(i, i, num = len(t1))\n",
    "    t4 = np.linspace(i, i, num = len(t2))\n",
    "\n",
    "    # print(t1)\n",
    "    \n",
    "    if(len(t1)==len(t5)):\n",
    "        full_docs = np.append(full_docs, t3)\n",
    "        summ_docs = np.append(summ_docs, t4)\n",
    "        full_sent = pd.concat([full_sent, t1], ignore_index=True)\n",
    "        summ_sent = pd.concat([summ_sent, t2], ignore_index=True)\n",
    "        ori_sent = pd.concat([ori_sent, t5], ignore_index=True)\n",
    "    else:\n",
    "        print(\"Doc No. : \", i,\"has a problem\")\n",
    "  \n",
    "  else:\n",
    "    full = temp['full'].iloc[i]\n",
    "    v = full.split(\"*\")    \n",
    "    t1 = pd.DataFrame(v)\n",
    "\n",
    "    ori = temp['full_orignal'].iloc[i]\n",
    "    v = ori.split('*')\n",
    "    t5 = pd.DataFrame(v)\n",
    "\n",
    "    t3 = np.linspace(i, i, num = len(t1))\n",
    "\n",
    "    if(len(t1)==len(t5)):\n",
    "        GS_docs = np.append(GS_docs, t3)\n",
    "        GS_sent = pd.concat([GS_sent, t1], ignore_index=True)\n",
    "        GS_ori_sent = pd.concat([GS_ori_sent, t5], ignore_index=True)\n",
    "    else:\n",
    "      print(\"GS Doc No. : \", i-1060,\"has a problem\")\n",
    "\n",
    "print('summary sentence tokenization')\n",
    "print(len(summ_docs))\n",
    "print(len(summ_sent))\n",
    "print(len(full_docs))\n",
    "print(len(full_sent))\n",
    "print(len(ori_sent))\n",
    "\n",
    "print(len(GS_docs))\n",
    "print(len(GS_sent))\n",
    "print(len(GS_ori_sent))\n",
    "\n",
    "# summ_sent_mod = pd.DataFrame(summ_sent, columns=['Summary_Sentences'])\n",
    "summ_sent_mod = summ_sent.set_axis(['Sentences'], axis=1)\n",
    "# summ_sent_mod\n",
    "\n",
    "full_sent_mod = full_sent.set_axis(['Sentences'], axis=1)\n",
    "# full_sent_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88149, 1)\n"
     ]
    }
   ],
   "source": [
    "# combining summary and full-text sentences for tfidf vectorization of sentences\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "GS_sent_mod = GS_sent.set_axis(['Sentences'], axis=1)\n",
    "\n",
    "tmp1 = pd.DataFrame(summ_sent_mod)\n",
    "tmp2 = pd.DataFrame(full_sent_mod)\n",
    "tmp3 = pd.DataFrame(GS_sent_mod)\n",
    "combined = pd.concat([tmp1, tmp2], axis = 0, ignore_index=True, sort = False)\n",
    "combined = pd.concat([combined, tmp3], axis = 0, ignore_index=True, sort = False)\n",
    "combined.columns = ['sents']\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(88149, 13753)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer as tuttu\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import scipy\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "token = RegexpTokenizer(r'[a-zA-Z0-9]+')\n",
    "tfidf_func = tuttu(ngram_range = (1, 1), tokenizer = token.tokenize, lowercase = True)\n",
    "tfidf = tfidf_func.fit_transform(combined['sents'])\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88149, 100)\n",
      "[[ 0.22565694  0.1963993   0.08186305 ... -0.02329515 -0.05306991\n",
      "  -0.02379196]\n",
      " [ 0.02082092  0.05376391 -0.00826877 ... -0.02675301  0.04439438\n",
      "  -0.07184504]\n",
      " [ 0.06535842  0.16459737  0.03341565 ...  0.05024299  0.02298391\n",
      "   0.00387506]\n",
      " ...\n",
      " [ 0.09605587  0.04584491 -0.04333802 ...  0.05675515 -0.04230288\n",
      "   0.01556567]\n",
      " [ 0.15883919  0.03815834 -0.06392485 ... -0.00491632  0.00254754\n",
      "  -0.01162616]\n",
      " [ 0.21907944  0.0343309  -0.05066817 ... -0.08739979 -0.09183262\n",
      "   0.03163885]]\n"
     ]
    }
   ],
   "source": [
    "# dimension reduction\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(100)\n",
    "a = svd.fit_transform(tfidf[:,:])\n",
    "\n",
    "del tfidf\n",
    "\n",
    "print(a.shape)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column no :  0  done!\n",
      "column no :  20  done!\n",
      "column no :  40  done!\n",
      "column no :  60  done!\n",
      "column no :  80  done!\n",
      "Mem. usage decreased to 16.81 Mb (75.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "# ## Function to reduce the DF size\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "     numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "     start_mem = df.memory_usage().sum() / 1024**2    \n",
    "     for col in df.columns:\n",
    "         col_type = df[col].dtypes\n",
    "         if col_type in numerics:\n",
    "             c_min = df[col].min()\n",
    "             c_max = df[col].max()\n",
    "             if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                 df[col] = df[col].astype(np.float16)\n",
    "             elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                 df[col] = df[col].astype(np.float32)\n",
    "             else:\n",
    "                 df[col] = df[col].astype(np.float64)  \n",
    "         if(col%20==0):\n",
    "             print(\"column no : \", col, \" done!\")\n",
    "     end_mem = df.memory_usage().sum() / 1024**2\n",
    "     if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "     return df\n",
    "\n",
    "x2 = pd.DataFrame(a)\n",
    "x2 = reduce_mem_usage(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88149, 100)\n",
      "14361\n",
      "69069\n",
      "4719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prati\\AppData\\Local\\Temp\\ipykernel_13200\\1545955771.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  summ_tfidf['doc_id'] = summ_docs\n",
      "C:\\Users\\prati\\AppData\\Local\\Temp\\ipykernel_13200\\1545955771.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  full_tfidf['doc_id'] = full_docs\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (69069) does not match length of index (4719)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m summ_tfidf[\u001b[39m'\u001b[39m\u001b[39mdoc_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m summ_docs\n\u001b[0;32m     13\u001b[0m full_tfidf[\u001b[39m'\u001b[39m\u001b[39mdoc_id\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m full_docs\n\u001b[1;32m---> 14\u001b[0m GS_tfidf[\u001b[39m'\u001b[39;49m\u001b[39mdoc_id\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m full_docs\n\u001b[0;32m     16\u001b[0m full_tfidf\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:3960\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3957\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3958\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3959\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3960\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4153\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4143\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4144\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4145\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4146\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4151\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4152\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4153\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   4155\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   4156\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   4157\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   4158\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   4159\u001b[0m     ):\n\u001b[0;32m   4160\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4161\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\frame.py:4880\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4877\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(Series(value), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4879\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4880\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4881\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\pandas\\core\\common.py:576\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    572\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    573\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    574\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    575\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    581\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (69069) does not match length of index (4719)"
     ]
    }
   ],
   "source": [
    "x2 = pd.DataFrame(a)\n",
    "print(x2.shape)\n",
    "\n",
    "summ_tfidf = x2.iloc[:len(summ_sent_mod)]\n",
    "full_tfidf = x2.iloc[len(summ_sent_mod):len(summ_sent_mod)+len(full_sent_mod)]\n",
    "GS_tfidf = x2.iloc[len(summ_sent_mod)+len(full_sent_mod):]\n",
    "\n",
    "print(len(summ_docs))\n",
    "print(len(full_docs))\n",
    "print(len(GS_docs))\n",
    "\n",
    "summ_tfidf['doc_id'] = summ_docs\n",
    "full_tfidf['doc_id'] = full_docs\n",
    "GS_tfidf['doc_id'] = full_docs\n",
    "\n",
    "full_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>doc_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.291654</td>\n",
       "      <td>0.337911</td>\n",
       "      <td>-0.352328</td>\n",
       "      <td>0.026092</td>\n",
       "      <td>-0.061148</td>\n",
       "      <td>-0.151230</td>\n",
       "      <td>-0.025926</td>\n",
       "      <td>-0.027003</td>\n",
       "      <td>0.180599</td>\n",
       "      <td>0.499574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005921</td>\n",
       "      <td>-0.016160</td>\n",
       "      <td>-0.002281</td>\n",
       "      <td>-0.039735</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.034441</td>\n",
       "      <td>0.032210</td>\n",
       "      <td>-0.010578</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.908179</td>\n",
       "      <td>-0.039031</td>\n",
       "      <td>0.381643</td>\n",
       "      <td>0.104143</td>\n",
       "      <td>-0.088458</td>\n",
       "      <td>-0.008414</td>\n",
       "      <td>-0.066026</td>\n",
       "      <td>-0.035028</td>\n",
       "      <td>-0.007140</td>\n",
       "      <td>0.011554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000935</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>-0.001899</td>\n",
       "      <td>-0.000103</td>\n",
       "      <td>-0.001151</td>\n",
       "      <td>0.001490</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>-0.000242</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.589366</td>\n",
       "      <td>0.595178</td>\n",
       "      <td>0.366344</td>\n",
       "      <td>0.110815</td>\n",
       "      <td>-0.190910</td>\n",
       "      <td>-0.078412</td>\n",
       "      <td>-0.056805</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>0.261873</td>\n",
       "      <td>-0.137452</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.007833</td>\n",
       "      <td>-0.001594</td>\n",
       "      <td>-0.009495</td>\n",
       "      <td>-0.001835</td>\n",
       "      <td>-0.005223</td>\n",
       "      <td>-0.002441</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000184</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.595866</td>\n",
       "      <td>0.475411</td>\n",
       "      <td>0.150358</td>\n",
       "      <td>-0.300221</td>\n",
       "      <td>-0.185160</td>\n",
       "      <td>-0.081711</td>\n",
       "      <td>-0.159151</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>-0.002887</td>\n",
       "      <td>-0.043346</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003814</td>\n",
       "      <td>0.001844</td>\n",
       "      <td>-0.002806</td>\n",
       "      <td>0.004271</td>\n",
       "      <td>0.005460</td>\n",
       "      <td>0.003665</td>\n",
       "      <td>-0.007210</td>\n",
       "      <td>0.012259</td>\n",
       "      <td>0.000770</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.755668</td>\n",
       "      <td>0.214197</td>\n",
       "      <td>-0.112009</td>\n",
       "      <td>0.059521</td>\n",
       "      <td>0.123883</td>\n",
       "      <td>-0.152595</td>\n",
       "      <td>0.115437</td>\n",
       "      <td>0.252762</td>\n",
       "      <td>0.169948</td>\n",
       "      <td>0.026277</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036788</td>\n",
       "      <td>-0.012525</td>\n",
       "      <td>-0.015120</td>\n",
       "      <td>0.012481</td>\n",
       "      <td>-0.047024</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>0.033480</td>\n",
       "      <td>-0.042091</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69064</th>\n",
       "      <td>0.251259</td>\n",
       "      <td>0.031353</td>\n",
       "      <td>-0.005674</td>\n",
       "      <td>-0.037892</td>\n",
       "      <td>0.393221</td>\n",
       "      <td>-0.028259</td>\n",
       "      <td>0.099534</td>\n",
       "      <td>-0.080244</td>\n",
       "      <td>-0.066602</td>\n",
       "      <td>-0.104945</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018986</td>\n",
       "      <td>0.015565</td>\n",
       "      <td>-0.099345</td>\n",
       "      <td>-0.024545</td>\n",
       "      <td>-0.000933</td>\n",
       "      <td>-0.099483</td>\n",
       "      <td>-0.105262</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.043113</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69065</th>\n",
       "      <td>0.621439</td>\n",
       "      <td>0.099535</td>\n",
       "      <td>-0.177858</td>\n",
       "      <td>-0.289408</td>\n",
       "      <td>-0.089541</td>\n",
       "      <td>-0.049983</td>\n",
       "      <td>0.048524</td>\n",
       "      <td>-0.084356</td>\n",
       "      <td>-0.090085</td>\n",
       "      <td>-0.084316</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043053</td>\n",
       "      <td>0.037947</td>\n",
       "      <td>-0.010430</td>\n",
       "      <td>0.084964</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>-0.066394</td>\n",
       "      <td>-0.003873</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>-0.014842</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69066</th>\n",
       "      <td>0.424294</td>\n",
       "      <td>0.226632</td>\n",
       "      <td>-0.150237</td>\n",
       "      <td>-0.301228</td>\n",
       "      <td>0.202872</td>\n",
       "      <td>-0.074265</td>\n",
       "      <td>0.067436</td>\n",
       "      <td>-0.077480</td>\n",
       "      <td>-0.087499</td>\n",
       "      <td>-0.122777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037815</td>\n",
       "      <td>0.061702</td>\n",
       "      <td>-0.068141</td>\n",
       "      <td>-0.021217</td>\n",
       "      <td>0.040708</td>\n",
       "      <td>-0.003964</td>\n",
       "      <td>0.044624</td>\n",
       "      <td>0.029112</td>\n",
       "      <td>0.098557</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69067</th>\n",
       "      <td>0.366167</td>\n",
       "      <td>0.185447</td>\n",
       "      <td>-0.228950</td>\n",
       "      <td>-0.068353</td>\n",
       "      <td>-0.049393</td>\n",
       "      <td>-0.028607</td>\n",
       "      <td>0.079945</td>\n",
       "      <td>-0.092737</td>\n",
       "      <td>-0.108417</td>\n",
       "      <td>-0.092146</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040396</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>-0.168673</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>-0.054390</td>\n",
       "      <td>-0.092447</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>-0.000612</td>\n",
       "      <td>0.126294</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69068</th>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.065595</td>\n",
       "      <td>-0.025008</td>\n",
       "      <td>-0.007761</td>\n",
       "      <td>0.010626</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>0.127505</td>\n",
       "      <td>-0.119878</td>\n",
       "      <td>-0.051424</td>\n",
       "      <td>0.032262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012870</td>\n",
       "      <td>-0.028069</td>\n",
       "      <td>-0.013075</td>\n",
       "      <td>-0.087140</td>\n",
       "      <td>-0.061698</td>\n",
       "      <td>-0.083337</td>\n",
       "      <td>0.081064</td>\n",
       "      <td>0.009721</td>\n",
       "      <td>-0.014113</td>\n",
       "      <td>599.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69069 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6   \n",
       "0      0.291654  0.337911 -0.352328  0.026092 -0.061148 -0.151230 -0.025926  \\\n",
       "1      0.908179 -0.039031  0.381643  0.104143 -0.088458 -0.008414 -0.066026   \n",
       "2      0.589366  0.595178  0.366344  0.110815 -0.190910 -0.078412 -0.056805   \n",
       "3      0.595866  0.475411  0.150358 -0.300221 -0.185160 -0.081711 -0.159151   \n",
       "4      0.755668  0.214197 -0.112009  0.059521  0.123883 -0.152595  0.115437   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "69064  0.251259  0.031353 -0.005674 -0.037892  0.393221 -0.028259  0.099534   \n",
       "69065  0.621439  0.099535 -0.177858 -0.289408 -0.089541 -0.049983  0.048524   \n",
       "69066  0.424294  0.226632 -0.150237 -0.301228  0.202872 -0.074265  0.067436   \n",
       "69067  0.366167  0.185447 -0.228950 -0.068353 -0.049393 -0.028607  0.079945   \n",
       "69068  0.022534  0.065595 -0.025008 -0.007761  0.010626  0.019376  0.127505   \n",
       "\n",
       "              7         8         9  ...        91        92        93   \n",
       "0     -0.027003  0.180599  0.499574  ...  0.005921 -0.016160 -0.002281  \\\n",
       "1     -0.035028 -0.007140  0.011554  ...  0.000935  0.000165 -0.001899   \n",
       "2     -0.015153  0.261873 -0.137452  ... -0.000770 -0.007833 -0.001594   \n",
       "3      0.023113 -0.002887 -0.043346  ...  0.003814  0.001844 -0.002806   \n",
       "4      0.252762  0.169948  0.026277  ...  0.036788 -0.012525 -0.015120   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "69064 -0.080244 -0.066602 -0.104945  ... -0.018986  0.015565 -0.099345   \n",
       "69065 -0.084356 -0.090085 -0.084316  ... -0.043053  0.037947 -0.010430   \n",
       "69066 -0.077480 -0.087499 -0.122777  ... -0.037815  0.061702 -0.068141   \n",
       "69067 -0.092737 -0.108417 -0.092146  ...  0.040396  0.038800 -0.168673   \n",
       "69068 -0.119878 -0.051424  0.032262  ...  0.012870 -0.028069 -0.013075   \n",
       "\n",
       "             94        95        96        97        98        99  doc_id  \n",
       "0     -0.039735  0.026600  0.034441  0.032210 -0.010578  0.005190     0.0  \n",
       "1     -0.000103 -0.001151  0.001490 -0.000977 -0.000242  0.002010     0.0  \n",
       "2     -0.009495 -0.001835 -0.005223 -0.002441 -0.000009 -0.000184     0.0  \n",
       "3      0.004271  0.005460  0.003665 -0.007210  0.012259  0.000770     0.0  \n",
       "4      0.012481 -0.047024 -0.004635  0.033480 -0.042091  0.006182     0.0  \n",
       "...         ...       ...       ...       ...       ...       ...     ...  \n",
       "69064 -0.024545 -0.000933 -0.099483 -0.105262  0.000295  0.043113   599.0  \n",
       "69065  0.084964  0.026843 -0.066394 -0.003873  0.032358 -0.014842   599.0  \n",
       "69066 -0.021217  0.040708 -0.003964  0.044624  0.029112  0.098557   599.0  \n",
       "69067  0.009373 -0.054390 -0.092447  0.016443 -0.000612  0.126294   599.0  \n",
       "69068 -0.087140 -0.061698 -0.083337  0.081064  0.009721 -0.014113   599.0  \n",
       "\n",
       "[69069 rows x 101 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "summ_tfidf_normalized = preprocessing.normalize(summ_tfidf.drop(['doc_id'], axis=1), norm='l2')\n",
    "summ_tfidf_normalized = pd.DataFrame(summ_tfidf_normalized)\n",
    "summ_tfidf_normalized.columns = summ_tfidf.drop(['doc_id'], axis=1).columns\n",
    "summ_tfidf_normalized['doc_id'] = np.array(summ_tfidf.doc_id)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "full_tfidf_normalized = preprocessing.normalize(full_tfidf.drop(['doc_id'], axis=1), norm='l2')\n",
    "full_tfidf_normalized = pd.DataFrame(full_tfidf_normalized)\n",
    "full_tfidf_normalized.columns = full_tfidf.drop(['doc_id'], axis=1).columns\n",
    "full_tfidf_normalized['doc_id'] = np.array(full_tfidf.doc_id)\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------------------------------\n",
    "import pickle\n",
    "\n",
    "# define the file path and name\n",
    "filename = 'summ_tfidf_normalizedd.pickle'\n",
    "\n",
    "# open a file in binary write mode\n",
    "with open(filename, 'wb') as f:\n",
    "    # serialize and write the dataframe to the file\n",
    "    pickle.dump(summ_tfidf_normalized, f)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------------------------------------------------\n",
    "full_tfidf_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
